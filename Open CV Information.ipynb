{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# READS IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('puppy.jpg')\n",
    "\n",
    "#TO PRINT THE IMAGE, USE THIS\n",
    "\n",
    "cv2.imshow(\"Output\",img)\n",
    "\n",
    "# 0 Means the window will not close and 1 means Millisecond here\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR VIDEO RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#Capture Video in variable\n",
    "\n",
    "cap = cv2.VideoCapture(\"sample.mp4\")\n",
    "\n",
    "while True:\n",
    "    #Here img reads the frame per second and success tells us whether the frame was stored successfully in img\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Video\",img)\n",
    "    if cv2.waitKey(0) & 0xFF ==ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR WEBCAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#3 sets the width\n",
    "cap.set(3,640)\n",
    "#4 sets the height\n",
    "cap.set(4,480)\n",
    "#10 sets the brightness\n",
    "cap.set(10,50)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Video\",img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Color Channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"puppy.jpg\")\n",
    "#Kernel Imported\n",
    "\n",
    "#Converts Color\n",
    "imggray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Converts the image into Blurred Image wtih 7x7 size..NOTE @@@@ Keep the value odd such as 7,7 or 5,5 or 3,3\n",
    "imgblur = cv2.GaussianBlur(imggray,(7,7),0)\n",
    "\n",
    "#To find edges of our image\n",
    "imgcanny = cv2.Canny(img,100,100)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Gray Image\",imggray)\n",
    "cv2.imshow(\"Blur Image\",imgblur)\n",
    "cv2.imshow(\"Edges of Image\",imgcanny)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To increase image dialation, you need a KERNEL(MATRIX), so import NUMPY\n",
    "import numpy as np\n",
    "#np.uint8 means a maximum of 256 values\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "#Dilate is used to increase the thickness of features\n",
    "imgdialation = cv2.dilate(imgcanny,kernel,iterations=1)\n",
    "#Erode is used to limit the thickness of features \n",
    "imgerode = cv2.erode(imgdialation,kernel,iterations=1)\n",
    "\n",
    "cv2.imshow(\"Dialation Image\",imgdialation)\n",
    "cv2.imshow(\"Eroded Image\",imgerode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESIZING AND CROPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 246, 3)\n",
      "(200, 300, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('puppy.jpg')\n",
    "print(img.shape)\n",
    "\n",
    "imgres = cv2.resize(img,(300,200))\n",
    "print(imgres.shape)\n",
    "# HEIGHT PARAMETER AND THEN WIDTH PARTAMETER\n",
    "imgcrop = img[0:200,150:200]\n",
    "cv2.imshow(\"Image\",imgres)\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.imshow(\"Cropped Image\",imgcrop)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMING PICTURES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#WITH 512 and 512, it is grayscale image and adding 3 makes is coloured\n",
    "img = np.zeros((512,512,3),np.uint8)\n",
    "\n",
    "#255 in first shows blue scale image.\n",
    "#img[:] = 255,0,0\n",
    "\n",
    "#this shows image in a box\n",
    "img[200:300,100:300] = 255,0,0\n",
    "\n",
    "#(0,0) represents starting pt of line, (300,300) represents end pt of life and ((0,255,0),3) represents color\n",
    "cv2.line(img,(0,0),(300,300),(0,255,0),3)\n",
    "# If you want a line till the end, use this......img.shape[1] represents width and img.shape[0] represents height\n",
    "cv2.line(img,(0,0),(img.shape[1],img.shape[0]),(0,255,0),3)\n",
    "\n",
    "#(0,0) represents starting, (250,350) represents end, (0,0,255) represents color and ,5 represents thickness\n",
    "cv2.rectangle(img,(0,0),(250,350),(0,0,255),5)\n",
    "cv2.rectangle(img,(0,0),(250,350),(0,0,255),cv2.FILLED)\n",
    "\n",
    "#(400,50) is mid point of circle, 30 is radius, (255,255,0) is color and 5 is thickness\n",
    "cv2.circle(img,(400,50),30,(255,255,0),5)\n",
    "\n",
    "#(300,100)pt. to start text, font, format, color and thickness\n",
    "cv2.putText(img,\" OPENCV \",(300,100),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,0),1)\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp Perspective\n",
    "Basically this helps pick out a particular coordinates of the image from the original image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"puppy.jpg\")\n",
    "\n",
    "width,height = 250,350\n",
    "\n",
    "pts1 = np.float32([[5,150],[10,200],[50,150],[60,250]])\n",
    "pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "imgoutput = cv2.warpPerspective(img,matrix,(width,height))\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.imshow('Output',imgoutput)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"puppy.jpg\")\n",
    "\n",
    "imgHor = np.hstack((img,img))\n",
    "imgVer = np.vstack((img,img))\n",
    "\n",
    "cv2.imshow(\"Stacked Horizontal Image\",imgHor)\n",
    "cv2.imshow(\"Stacked Vertical Image\",imgVer)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4e66c9581c3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mimgHSV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mh_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hue Min\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"TrackBars\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mh_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hue Max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TrackBars\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "def empty(a):\n",
    "    pass\n",
    " \n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    " \n",
    " \n",
    "path = 'puppy.png'\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\",640,240)\n",
    "cv2.createTrackbar(\"Hue Min\",\"TrackBars\",0,179,empty)\n",
    "cv2.createTrackbar(\"Hue Max\",\"TrackBars\",19,179,empty)\n",
    "cv2.createTrackbar(\"Sat Min\",\"TrackBars\",110,255,empty)\n",
    "cv2.createTrackbar(\"Sat Max\",\"TrackBars\",240,255,empty)\n",
    "cv2.createTrackbar(\"Val Min\",\"TrackBars\",153,255,empty)\n",
    "cv2.createTrackbar(\"Val Max\",\"TrackBars\",255,255,empty)\n",
    " \n",
    "while True:\n",
    "    img = cv2.imread(path)\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"TrackBars\")\n",
    "    print(h_min,h_max,s_min,s_max,v_min,v_max)\n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    imgResult = cv2.bitwise_and(img,img,mask=mask)\n",
    " \n",
    " \n",
    "    # cv2.imshow(\"Original\",img)\n",
    "    # cv2.imshow(\"HSV\",imgHSV)\n",
    "    # cv2.imshow(\"Mask\", mask)\n",
    "    # cv2.imshow(\"Result\", imgResult)\n",
    " \n",
    "    imgStack = stackImages(0.6,([img,imgHSV],[mask,imgResult]))\n",
    "    cv2.imshow(\"Stacked Images\", imgStack)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picture Stacking Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Detection and Contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3593.5\n",
      "8\n",
      "8619.0\n",
      "4\n",
      "10398.5\n",
      "4\n",
      "10236.0\n",
      "8\n",
      "1612.5\n",
      "3\n",
      "10402.0\n",
      "4\n",
      "6389.0\n",
      "4\n",
      "5629.0\n",
      "3\n",
      "3475.5\n",
      "4\n",
      "2270.5\n",
      "4\n",
      "3552.5\n",
      "8\n",
      "8674.0\n",
      "4\n",
      "2646.0\n",
      "4\n",
      "5690.5\n",
      "3\n",
      "10234.0\n",
      "8\n",
      "5712.0\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    " \n",
    "def getContours(img):\n",
    "    #The 'RETR_EXTERNAL' finds the outer contours \n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    #This finds an iteration for contours in canny images searched through all contours\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        #Till here it draws a contour around images\n",
    "        \n",
    "        #If area is > 500, then it discards the shapes\n",
    "        if area>500:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n",
    "            \n",
    "            #Finds the perimeter of contours and the 'True' means the contours are closed.\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            #print(peri)\n",
    "            \n",
    "            #Gives the corner points of Contours and 'True' means that the contours are closed.\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            #The length of 'approx' means the overall length of contour by taking end points\n",
    "            print(len(approx))\n",
    "            \n",
    "            #This gives a bounding box around the contours\n",
    "            objCor = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            \n",
    " \n",
    "             \n",
    "            if objCor ==3: objectType =\"Tri\"\n",
    "            elif objCor == 4:\n",
    "                aspRatio = w/float(h)\n",
    "                if aspRatio >0.98 and aspRatio <1.03: objectType= \"Square\"\n",
    "                else:objectType=\"Rectangle\"\n",
    "            elif objCor>4: objectType= \"Circles\"\n",
    "            else:objectType=\"None\"\n",
    " \n",
    " \n",
    "            #This puts a rectangle contour at the particular coordinate \n",
    "            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            #The \"(x+(w//2)-10)\" and \"(y+(h//2)-10)\" are used to select the coordinates where text starts\n",
    "            cv2.putText(imgContour,objectType,\n",
    "                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,\n",
    "                        (0,0,0),2)\n",
    " \n",
    " \n",
    "path = 'shapes.png'\n",
    "img = cv2.imread(path)\n",
    "\n",
    "#copies the original image to be passed to image contour\n",
    "imgContour = img.copy()\n",
    " \n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\n",
    "imgCanny = cv2.Canny(imgBlur,50,50)\n",
    "getContours(imgCanny)\n",
    " \n",
    "imgBlank = np.zeros_like(img)\n",
    "imgStack = stackImages(0.5,([img,imgGray,imgBlur],\n",
    "                            [imgCanny,imgContour,imgBlank]))\n",
    " \n",
    "cv2.imshow(\"Stack\", imgStack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread('1.jpg')\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(imgGray,1.1,4)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow(\"Result\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
