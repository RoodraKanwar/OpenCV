{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Scanner\n",
    "This can Scan computer pictures from a good resolution camera ignoring the other details present around the screen. It can also scan a page provided the angle and resolution of camera is helpful for proper Image assessment. I have also attached an output.\n",
    "\n",
    "\n",
    "Furthermore, this can also be used on a live WebCam and Camera but the resolution has to be good otherwise it won't fetch the details. As I didn't have a good quality camera, I went ahead with normal picture uploading and checking.\n",
    "\n",
    "\n",
    "I learned OpenCV from several YouTube tutorials and many of my concepts have been taken from them. I have also made several codes for different tasks and they are uploaded on my GitHub for future use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#The width and height parameters are used for resizing the image. This is stored in dimensions to be used later on\n",
    "\n",
    "widthImg=1500\n",
    "heightImg =1200\n",
    "dims = (widthImg,heightImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Image to include Blur and Canny Edge for Edge Detection\n",
    "\n",
    "1.) imgGray is used to convert image into GrayScale as Blur and Canny Edges are applied on GrayScale.\n",
    "\n",
    "2.) GaussianBlur is used to include Noise inside the image.\n",
    "\n",
    "3.) Canny Edge Detection is used for finding edges of objects in images.\n",
    "\n",
    "4.) Kernel is used for Dilation and to erode the lines inside the Images. This makes the lines inside images a   bit more wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(img):\n",
    "    Gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    Blur = cv2.GaussianBlur(Gray,(5,5),1)\n",
    "    Canny = cv2.Canny(Blur,200,200)\n",
    "    kernel = np.ones((5,5))\n",
    "    Dial = cv2.dilate(Canny,kernel,iterations=2)\n",
    "    Thres = cv2.erode(Dial,kernel,iterations=1)\n",
    "    return Thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting contours around objects in images\n",
    "1.) \"Biggest\" variable here stores the Numerical array values for objects. This means that if any object detected is larger than previous value, it will replace the previous value.\n",
    "\n",
    "2.) \"contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\" ==> This is used to find all the contours present inside the image and store it in contours.\n",
    "\n",
    "3.) A loop is passed so that all contours are iterated.\n",
    "\n",
    "4.) Area variable is used to store contourAreas that are being iterated over in the loop. This means, new values will be successively passed into the loop.\n",
    "\n",
    "5.) Minimum threshold for area is kept and if the area of a contour is more than the threshold, it is stored inside perimeter.\n",
    "\n",
    "6.) Approx variable is used such that points are generated which is to be used to find the feature points of contours. \n",
    "\n",
    "7.) At the end, Contours are drawn around the feature points and the copy of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Contour(img):\n",
    "    biggest = np.array([])\n",
    "    mArea = 0\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>50:\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            if area > mArea and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                mArea = area\n",
    "    cv2.drawContours(imgContour, biggest, -1, (255, 0, 0), 20)\n",
    "    return biggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reordering of feature points of the Biggest Contour found in getContours() function\n",
    "1.) The reshape function is used to split the feature points into 4 ROWS and 2 COLUMNS such that 4 points are found.\n",
    "\n",
    "2.) np.zeros makes a new array of 4 ROWS and 2 COLUMNS with data type of 32 bit integer.\n",
    "\n",
    "3.) myPoints.sum(1) is used to adding all the numerical values of features points into a single value accross a row. This is done because of following reason ==> The highest value for a particular row suggests that the point is end point for contour. Similarly, the lowest value represents the starting point. The 3rd and 4th point can be found by addition and subtraction.\n",
    "\n",
    "4.)np.argmin(add) returns the Indices of lowest value inside the new Array which means Starting Point.\n",
    "Similarly, the highest value is returned for the end point which is the third Index.\n",
    "\n",
    "5.)Similarly for the left and right coordinates, the minimum and maximum difference is taken from subtraction of array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder (myPt):\n",
    "    myPt = myPt.reshape((4,2))\n",
    "    myPtNew = np.zeros((4,1,2),np.int32)\n",
    "    add = myPt.sum(1)\n",
    "    myPtNew[0] = myPt[np.argmin(add)]\n",
    "    myPtNew[3] = myPt[np.argmax(add)]\n",
    "    diff = np.diff(myPt,axis=1)\n",
    "    myPtNew[1] = myPt[np.argmin(diff)]\n",
    "    myPtNew[2] = myPt[np.argmax(diff)]\n",
    "    return myPtNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warping of images \n",
    "The point 1 and point 2 are used for transformation. The point 2 consists of coordinates of the original image and the point 1 consits of the reordered feature points of the biggest contour\n",
    "\n",
    "2.) matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    imgOutput = cv2.warpPerspective(img, matrix, (widthImg, heightImg))\n",
    "    This is used to create the matrix and then finally the image is wrapped into using the original frame and the \n",
    "    matrix just created.\n",
    "    \n",
    "3.) At the end, the image is resized again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Warp(img,biggest):\n",
    "    biggest = reorder(biggest)\n",
    "    pts1 = np.float32(biggest)\n",
    "    pts2 = np.float32([[0, 0], [widthImg, 0], [0, heightImg], [widthImg, heightImg]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    imgOutput = cv2.warpPerspective(img, matrix, (widthImg, heightImg))\n",
    " \n",
    "    imgCropped = imgOutput[20:imgOutput.shape[0]-20,20:imgOutput.shape[1]-20]\n",
    "    imgCropped = cv2.resize(imgCropped,(widthImg,heightImg))\n",
    " \n",
    "    return imgCropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Images in Horizontal and Vertical Stacks\n",
    "This is something I used from the a blog post to make my task easier as it is cumbersome to merge grayScale image with a normal image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling functions and reading the images and outputting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = cv2.imread('note5.jpg') \n",
    "img = cv2.resize(img1,(widthImg,heightImg))\n",
    "imgContour = img.copy()\n",
    " \n",
    "imgThres = preProcessing(img)\n",
    "biggest = getContours(imgThres)\n",
    "if biggest.size !=0:\n",
    "    imgWarped=getWarp(img,biggest)\n",
    "    imageArray = ([imgContour, imgWarped, imgThres])\n",
    "else:\n",
    "    imageArray = ([imgContour, img,imgThres])\n",
    " \n",
    "stackedImages = stackImages(2,imageArray,)\n",
    "width = 1080\n",
    "height = 540\n",
    "final = cv2.resize(stackedImages,(width,height))\n",
    "cv2.imshow(\"WorkFlow\", final)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
